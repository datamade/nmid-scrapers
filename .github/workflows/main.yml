name: Scrape campaign finance data

on:
  schedule:
    - cron:  '15 2 * * *'    

  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        target: [
          disclosures.xlsx,
          candidate_committees.csv,
          candidate_committee_filings.csv,
          pac_committees.csv,
          pac_committee_filings.csv,
          independent_expenditures.xlsx, 
          lobbyist.xlsx, 
          lobbyist_employer.xlsx
        ]

    steps:
      - uses: actions/checkout@v4

      - name: Setup requirementss
        run: pip install -r requirements.txt

      - name: Make ${{ matrix.target }}
        run: make data/processed/${{ matrix.target }}

      - name: Upload ${{ matrix.target }} to S3
        env:
          S3BUCKET: ${{ secrets.S3BUCKET }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          aws s3 cp data/processed/${{ matrix.target }} $S3BUCKET --acl public-read


  import:
    if: '!cancelled()'
    needs: scrape
    runs-on: ubuntu-latest

    steps:
      - name: Trigger Openness Project ETL
        uses: peter-evans/repository-dispatch@v3
        with:
          token: ${{ secrets.PAT }}
          repository: datamade/openness-project-nmid
          event-type: nightly-scrape-done
